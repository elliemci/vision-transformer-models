{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwOoM65+3jZqd8NuhEtavO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliemci/vision-transformer-models/blob/main/model_deployment/mri_classification_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploying a MRI classification app with Huggingface and Gradio"
      ],
      "metadata": {
        "id": "gFWEZBZHdPdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "id": "1GOBcM4X8rZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "5P0Eqky58sLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/ColabNotebooks/ExplainableAI/model_deployment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1fRqtMAkiO",
        "outputId": "fb08d38d-378e-4c46-cab5-e05ed25f6f8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ColabNotebooks/ExplainableAI/model_deployment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create a Gradio App that exposes the MRI brain tumor classification model"
      ],
      "metadata": {
        "id": "C0DJDaC6dfn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m9ON-Z-HdBnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f7c424e2-134a-4544-b8a6-053729bd09a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://de2911cb3b502f8d15.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://de2911cb3b502f8d15.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://de2911cb3b502f8d15.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def update_gallery(images):\n",
        "    \"\"\"Update the gallery with the uploaded images\"\"\"\n",
        "    return images\n",
        "\n",
        "# create gradio instance demo\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center;'>MRI Brain Tumor Classification App</h1>\")\n",
        "    with gr.Column():\n",
        "        image_input = gr.Files(label=\"Upload MRI Images\",\n",
        "                              file_count=\"multiple\",\n",
        "                              type=\"filepath\")\n",
        "\n",
        "        gallery = gr.Gallery(label=\"MRI Brain Images\")\n",
        "\n",
        "    # set up an event listener to update the gallery images when image_input changes\n",
        "    image_input.change(\n",
        "        fn=update_gallery,\n",
        "        inputs=[image_input],\n",
        "        outputs=[gallery])\n",
        "\n",
        "# launch the app enabled to be debugged\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Gradio UI for MRI classification"
      ],
      "metadata": {
        "id": "K3jPTzzGfPzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Vision Transformer model trained for MRI classification and image processor"
      ],
      "metadata": {
        "id": "ka4KovwQf8_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTImageProcessor, ViTForImageClassification\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\"elliemci/vit_tumor_classification_model\")\n",
        "image_processor = ViTImageProcessor.from_pretrained(\"elliemci/vit_tumor_classification_model\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "0hXKXZrtfAt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Immage class prediction function"
      ],
      "metadata": {
        "id": "oxg3mZKAgXCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def predict(images):\n",
        "\n",
        "  batch_size = len([images]) if len(images) <= 8 else 8\n",
        "\n",
        "  # create the data loader for all input images\n",
        "  inputs_loader = DataLoader(images, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  batch_size = len([images]) if len(images) <= 8 else 8\n",
        "\n",
        "  # create the data loader for all input images\n",
        "  inputs_loader = DataLoader(images, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  predictions = []\n",
        "  # set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # disable gradient calculation during inference\n",
        "  with torch.no_grad():\n",
        "      for batch in inputs_loader:\n",
        "        # preprocess the batch of images using the feature extractor\n",
        "        inputs = image_processor(images=batch['image'], return_tensors=\"pt\").to(device)\n",
        "        inputs = batch['image'].to(device)\n",
        "        # with dictionary unpacking operator on preprocess data, containt pizel_values and labels\n",
        "        outputs = model(**inputs)\n",
        "        # outputs = model(pixel_values=inputs, labels=labels)\n",
        "        _, preds = torch.max(outputs.logits, 1)\n",
        "\n",
        "        # add individual prediction iterating over the list\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "  return predictions # {'tumor':str(predictions), 'no-tumor':str(1-predictions)}"
      ],
      "metadata": {
        "id": "q2-i74IrSrKw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio UI for uploading image, making and displaying the prediction"
      ],
      "metadata": {
        "id": "iR2uYExBgn14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path):\n",
        "  \"\"\" Takes the path to an image and returns the prediction of the model \"\"\"\n",
        "\n",
        "  try:\n",
        "    # open the image and convert to RGB format\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    # pre-process the image with the pre-trained image processor\n",
        "    input = image_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**input)\n",
        "      # extract the row outputs\n",
        "      logits = outputs.logits\n",
        "      predicted_class = logits.argmax(-1).item()\n",
        "      prediction = \"Tumor\" if predicted_class == 1 else \"No Tumor\"\n",
        "\n",
        "      return prediction\n",
        "\n",
        "  except Exception as e:\n",
        "    return f\"Error processing image: {e}\"\n",
        "\n",
        "\n",
        "def update_gallery(images):\n",
        "  \"\"\" Process the uploaded images and returns a list of image paths along with\n",
        "      their predictions. \"\"\"\n",
        "\n",
        "  predictions = []\n",
        "  image_paths = []\n",
        "\n",
        "  if images:\n",
        "    for image in images:\n",
        "      # extract the file path\n",
        "      image_path = image.name\n",
        "      image_paths.append(image_path)\n",
        "      # predict and store\n",
        "      prediction = predict_image(image_path)\n",
        "      predictions.append(prediction)\n",
        "\n",
        "  # gallery expects the input in the format (image_path, prediction) for every image,\n",
        "  # combine image_paths and predictions into a list of tuples (image_path, prediction)\n",
        "  image_paths_with_predictions = list(zip(image_paths, predictions))\n",
        "\n",
        "  return image_paths_with_predictions"
      ],
      "metadata": {
        "id": "pEI1Fc5Lil0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio Interface"
      ],
      "metadata": {
        "id": "wYQZw1ptsBO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create and lauch Gradio web interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center;'>MRI Brain Tumor Classification App</h1>\")\n",
        "\n",
        "    with gr.Column():\n",
        "      # create components\n",
        "      image_input = gr.Files(label=\"Upload MRI Images\",\n",
        "                            file_count=\"multiple\",\n",
        "                            type=\"filepath\")\n",
        "      gallery = gr.Gallery(label=\"MRI Brain Images with Predictions\")\n",
        "\n",
        "    # set up an event listener\n",
        "    image_input.change(\n",
        "        fn=update_gallery,\n",
        "        inputs=[image_input],\n",
        "        outputs=[gallery]\n",
        "    )\n",
        "    # launch the app\n",
        "    demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "gaRcsVqWsAHN",
        "outputId": "eddfe68f-d420-4b66-bdad-d68c8305db56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://dc20b644505a65352f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dc20b644505a65352f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://dc20b644505a65352f.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gradio UI for MEI segmentation"
      ],
      "metadata": {
        "id": "c5TSXAiohEes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image segmentation prediction function"
      ],
      "metadata": {
        "id": "7nLthrYOhtrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio UI for uploading image and making a prediction"
      ],
      "metadata": {
        "id": "sg7SNkikiDHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio components to display segmentation result"
      ],
      "metadata": {
        "id": "pldgv7_AiZ-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Gradio Interface"
      ],
      "metadata": {
        "id": "iRfLC6G5ij94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### App contents"
      ],
      "metadata": {
        "id": "IMvDONAIiqBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text section"
      ],
      "metadata": {
        "id": "pz6_6Ti6i0Vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gallery section"
      ],
      "metadata": {
        "id": "G3ToCQh0i37P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Image analysis section"
      ],
      "metadata": {
        "id": "nmDKrz1Di83Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### App"
      ],
      "metadata": {
        "id": "e-IqoMibjhtu"
      }
    }
  ]
}