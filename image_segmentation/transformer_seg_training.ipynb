{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "transformer_seg_training.ipynb",
      "authorship_tag": "ABX9TyPmSFxROydKtP756dyf8ZbJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64d62040442641eebc77c3338dc87321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a43c862cf5a4fcbb9be9a78dc708ffc",
              "IPY_MODEL_5f2455303d42459c889ab92ca010091f",
              "IPY_MODEL_40c0272c64d5462c9bb6b339fc90a973"
            ],
            "layout": "IPY_MODEL_090f2ea1de80453fae7f9508d7c206a8"
          }
        },
        "4a43c862cf5a4fcbb9be9a78dc708ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a2bb1fa5ff46b8972b73f66d9dc010",
            "placeholder": "​",
            "style": "IPY_MODEL_c916ff666899449e9e601ca3247044f0",
            "value": "config.json: 100%"
          }
        },
        "5f2455303d42459c889ab92ca010091f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d4230fd0404fb9bacbb0fafddc9121",
            "max": 6884,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d018b28bdf342bf96f641160ee4d898",
            "value": 6884
          }
        },
        "40c0272c64d5462c9bb6b339fc90a973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec735724b73d42b58dc8dd37a86eca9d",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a88b7622a44d9883fbc42f5171a341",
            "value": " 6.88k/6.88k [00:00&lt;00:00, 366kB/s]"
          }
        },
        "090f2ea1de80453fae7f9508d7c206a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a2bb1fa5ff46b8972b73f66d9dc010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c916ff666899449e9e601ca3247044f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d4230fd0404fb9bacbb0fafddc9121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d018b28bdf342bf96f641160ee4d898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec735724b73d42b58dc8dd37a86eca9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a88b7622a44d9883fbc42f5171a341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04a983556de54f3184b37751afb2296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e871a05b678a43909adb5a7a84c7dfb4",
              "IPY_MODEL_6c668801f4f848e3adf0972b607ae8a1",
              "IPY_MODEL_f0002808f2b94f46b1c5caf8e721cb23"
            ],
            "layout": "IPY_MODEL_923972a4949e4095b24a3fdadb850d15"
          }
        },
        "e871a05b678a43909adb5a7a84c7dfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eab1959a1ef497c8e489575d27004ab",
            "placeholder": "​",
            "style": "IPY_MODEL_448edf688a2a4f97830f9cdb2d78bfd7",
            "value": "model.safetensors: 100%"
          }
        },
        "6c668801f4f848e3adf0972b607ae8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b80073ef39a4f0da25ccaec1725a4f4",
            "max": 15036944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c044c1728e6845b2a031a3b2454bc14a",
            "value": 15036944
          }
        },
        "f0002808f2b94f46b1c5caf8e721cb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfc9c27b65b4b36bfa1de39c43ad7e8",
            "placeholder": "​",
            "style": "IPY_MODEL_a59b6ef6319044d483db3cfda7479d58",
            "value": " 15.0M/15.0M [00:00&lt;00:00, 42.7MB/s]"
          }
        },
        "923972a4949e4095b24a3fdadb850d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eab1959a1ef497c8e489575d27004ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448edf688a2a4f97830f9cdb2d78bfd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b80073ef39a4f0da25ccaec1725a4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c044c1728e6845b2a031a3b2454bc14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdfc9c27b65b4b36bfa1de39c43ad7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a59b6ef6319044d483db3cfda7479d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliemci/vision-transformer-models/blob/main/image_segmentation/transformer_seg_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MRI image segmentation with SegFormer"
      ],
      "metadata": {
        "id": "sR-8-pXvkZ9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a deep-learning-based semantic segmentation transformer model to identify the tumor locations and boundaries within MRI brain images, using brain images and coresponding ground truth masks. Pnce trained, SegFormer can predict bounderies of tumor regions. A segmentation accuracy metric Mean IoU is appliced to asses model quality."
      ],
      "metadata": {
        "id": "5FWn2EVVkD2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jedi"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QvJ-OnyHshsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install libcairo2-dev pkg-config python3-dev"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kHcWKIV9skvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycairo"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lxB1ChMnsnhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec==2024.10.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pzDTnejZseQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36bc1cf-31dc-4826-eac6-9c6aed1de0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec==2024.10.0 in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFZVve1ziT2K",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvF8rXbQiV-M",
        "outputId": "8099a4a9-6f29-4815-9e03-4ddda2d80e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/ExplainableAI/image_segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKsOx_UtimIq",
        "outputId": "d14fe324-f7cf-49f4-a61c-9752bd72d655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/ExplainableAI/image_segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsZzcxS3jGhD",
        "outputId": "f6cf2731-6b2e-4201-9ae0-475e4bf4b89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_preproces.ipynb  mri_data_seg  segmentation_dataset  transformer_seg_traiining.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load MRI dataset"
      ],
      "metadata": {
        "id": "Vf-ot4dHlWoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is a dictionary containg the images and coresponding masks, split into train, test and validate datasets."
      ],
      "metadata": {
        "id": "7tXykZiMl4qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "dataset = load_from_disk(\"segmentation_dataset\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "EFTiC4ixjIbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7a8f4d-ff88-4923-cd42-c8c9966329f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['pixel_values', 'label'],\n",
              "        num_rows: 400\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['pixel_values', 'label'],\n",
              "        num_rows: 200\n",
              "    })\n",
              "    validate: Dataset({\n",
              "        features: ['pixel_values', 'label'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training Function"
      ],
      "metadata": {
        "id": "25ZiC4EoMZYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Hugging Face SegFormer model"
      ],
      "metadata": {
        "id": "ijkE10MlNFZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# SegformerForSemanticSegmentation model is not competable with 2-class segmentation task\n",
        "from transformers import SegformerForSemanticSegmentation\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def list_and_set_gpu_memory_growth():\n",
        "    \"\"\"\n",
        "    Lists available GPUs and sets memory growth for each GPU.\n",
        "    \"\"\"\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        num_gpus = torch.cuda.device_count()\n",
        "        print(f\"Number of available GPUs: {num_gpus}\")\n",
        "\n",
        "        for i in range(num_gpus):\n",
        "            gpu_properties = torch.cuda.get_device_properties(i)\n",
        "            print(f\"GPU {i}: {gpu_properties.name}\")\n",
        "\n",
        "            # Enable memory growth for this GPU\n",
        "            torch.cuda.set_per_process_memory_fraction(1.0, device=i)\n",
        "            #torch.cuda.empty_cache()\n",
        "\n",
        "            # Check if memory growth is enabled (optional)\n",
        "            #is_memory_growth_enabled = torch.cuda.is_memory_growth_enabled(i)  # PyTorch 2.0+\n",
        "            #print(f\"  Memory growth enabled: {is_memory_growth_enabled}\")\n",
        "    else:\n",
        "        print(\"CUDA is not available.\")\n",
        "\n",
        "# Call the function to list and set memory growth\n",
        "list_and_set_gpu_memory_growth()\n",
        "\n",
        "# initialize the model\n",
        "model_checkpoint = \"nvidia/segformer-b0-finetuned-ade-512-512\"\n",
        "# load the SegformaerForSemanticSegmentation\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels = 2,\n",
        "    id2label = {0: 'background', 1: 'tumor'},\n",
        "    label2id = {'background': 0, 'tumor': 1},\n",
        "    ignore_mismatched_sizes = True\n",
        ")\n",
        "\n",
        "# set hyperparameters for training\n",
        "batch_size = 2\n",
        "num_epochs = 2\n",
        "num_training_steps = (len(dataset['train'])//batch_size) * num_epochs\n",
        "learning_rate = 6e-5\n",
        "weight_decay_rate = 0.01\n",
        "\n",
        "# compile the model\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr=learning_rate,\n",
        "                              weight_decay=weight_decay_rate)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = num_training_steps)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "64d62040442641eebc77c3338dc87321",
            "4a43c862cf5a4fcbb9be9a78dc708ffc",
            "5f2455303d42459c889ab92ca010091f",
            "40c0272c64d5462c9bb6b339fc90a973",
            "090f2ea1de80453fae7f9508d7c206a8",
            "52a2bb1fa5ff46b8972b73f66d9dc010",
            "c916ff666899449e9e601ca3247044f0",
            "61d4230fd0404fb9bacbb0fafddc9121",
            "6d018b28bdf342bf96f641160ee4d898",
            "ec735724b73d42b58dc8dd37a86eca9d",
            "d9a88b7622a44d9883fbc42f5171a341",
            "04a983556de54f3184b37751afb2296c",
            "e871a05b678a43909adb5a7a84c7dfb4",
            "6c668801f4f848e3adf0972b607ae8a1",
            "f0002808f2b94f46b1c5caf8e721cb23",
            "923972a4949e4095b24a3fdadb850d15",
            "2eab1959a1ef497c8e489575d27004ab",
            "448edf688a2a4f97830f9cdb2d78bfd7",
            "9b80073ef39a4f0da25ccaec1725a4f4",
            "c044c1728e6845b2a031a3b2454bc14a",
            "fdfc9c27b65b4b36bfa1de39c43ad7e8",
            "a59b6ef6319044d483db3cfda7479d58"
          ]
        },
        "id": "K2mYaparrde3",
        "outputId": "472dcf46-44c2-40a2-8839-36394b841e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of available GPUs: 1\n",
            "GPU 0: Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/6.88k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64d62040442641eebc77c3338dc87321"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/15.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04a983556de54f3184b37751afb2296c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([2, 256, 1, 1]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up training arguments for initializing hyperparameters"
      ],
      "metadata": {
        "id": "GtVH5SO3NSab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "# define a transform to convert PIL images to PyTorch tensors\n",
        "transform = transforms.Compose([\n",
        "    # convert PIL image to PyTorch tensor\n",
        "    transforms.ToTensor(),  # convert PIL image to PyTorch tensor\n",
        "])\n",
        "\n",
        "def process_train_batch(batch):\n",
        "  \"\"\" Read an bath of train images and transform them into inputs.\n",
        "      Since transformer is pre-trained on RGB images convert from gray scale\"\"\"\n",
        "\n",
        "  batch_imgs = [transform(img.convert(\"RGB\")) for img in batch['pixel_values']]\n",
        "  batch_masks = [transform(mask.convert(\"RGB\")) for mask in batch['label']]\n",
        "\n",
        "  # return a dictionary with image and label data\n",
        "  return {'pixel_values': batch_imgs, 'mask': batch_masks}\n",
        "\n",
        "def process_val_batch(batch):\n",
        "  \"\"\" Read an bath of test images and transform them into inputs. \"\"\"\n",
        "  batch_imgs = [transform(img.convert(\"RGB\")) for img in batch['pixel_values']]\n",
        "  batch_masks = [transform(label.convert(\"RGB\")) for label in batch['label']]\n",
        "\n",
        "  # return a dictionary with image and label data\n",
        "  return {'pixel_values': batch_imgs, 'mask': batch_masks}\n",
        "\n",
        "dataset[\"train\"].set_transform(process_train_batch)\n",
        "dataset[\"test\"].set_transform(process_train_batch)\n",
        "dataset[\"validate\"].set_transform(process_val_batch)\n",
        "\n",
        "train_loader = DataLoader(dataset['train'], batch_size=batch_size, shuffle=True)\n",
        "train_loader = DataLoader(dataset['test'], batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset['validate'], batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "for batch in train_loader:\n",
        "  # convert each gray scale image in batch to RGB\n",
        "\n",
        "  print(f\"batch data type: {type(batch)}\")\n",
        "  print(f\"batch images size: {batch['pixel_values'].shape}\")\n",
        "  print(f\"batch masks size: {batch['mask'].shape}\")\n",
        "  print()\n",
        "  image = batch['pixel_values'][0]\n",
        "  mask = batch['mask'][0]\n",
        "  print(f\"image dimensions: {image.size}\")\n",
        "  print(f\"image data type: {image.dtype}\")\n",
        "  print(f\"image min value: {image.min()}\")\n",
        "  print(f\"image max value: {image.max()}\")\n",
        "  print(f\"labels in mask:, {np.unique(mask)}\")\n",
        "  print(f\"mask dimensions: {mask.size}\")\n",
        "  print(f\"mask data type: {mask.dtype}\")\n",
        "  print(f\"mask min value: {mask.min()}\")\n",
        "  print(f\"mask max value: {mask.max()}\")\n",
        "  print()\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzIAEdnO-y5",
        "outputId": "c1269521-a707-44c8-9c1f-578e36091f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch data type: <class 'dict'>\n",
            "batch images size: torch.Size([2, 3, 512, 512])\n",
            "batch masks size: torch.Size([2, 3, 512, 512])\n",
            "\n",
            "image dimensions: <built-in method size of Tensor object at 0x7e2449470720>\n",
            "image data type: torch.float32\n",
            "image min value: 0.0\n",
            "image max value: 1.0\n",
            "labels in mask:, [0. 1.]\n",
            "mask dimensions: <built-in method size of Tensor object at 0x7e24500f3060>\n",
            "mask data type: torch.float32\n",
            "mask min value: 0.0\n",
            "mask max value: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Accuracy Estimation"
      ],
      "metadata": {
        "id": "RGtocLEjMyBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(true_class, pred_class):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) for a specific class.\n",
        "    Args:\n",
        "        true_class (torch.Tensor): Boolean mask for the true class.\n",
        "        pred_class (torch.Tensor): Boolean mask for the predicted class.\n",
        "    Returns:\n",
        "        float: IoU score for the class.\n",
        "    \"\"\"\n",
        "\n",
        "    intersection = torch.logical_and(true_class, pred_class)\n",
        "    union = torch.logical_or(true_class, pred_class)\n",
        "\n",
        "    if torch.any(union):\n",
        "        iou = torch.sum(intersection).float() / torch.sum(union).float()\n",
        "    else:\n",
        "        iou = 0.0  # if no overlap\n",
        "    #print(f\"IoU: {iou}\")\n",
        "    #print()\n",
        "    return iou\n",
        "\n",
        "\n",
        "def calculate_mean_iou(true_mask, pred_mask):\n",
        "    \"\"\"\n",
        "    Calculate the mean Intersection over Union (mIoU) score.\n",
        "    Args:\n",
        "        true_mask (torch.Tensor): Ground truth mask.\n",
        "        pred_mask (torch.Tensor): Predicted mask.\n",
        "    Returns:\n",
        "        float: Mean IoU score across all classes.\n",
        "    \"\"\"\n",
        "\n",
        "    class_iou = []\n",
        "\n",
        "    # Get the maximum class value (assuming contiguous classes starting from 0)\n",
        "    max_value = true_mask.max().item()\n",
        "    #print(f\"Max class value: {max_value}\")\n",
        "\n",
        "    for i in range(1, max_value + 1):  # Skip background (class 0)\n",
        "        true_i = (true_mask == i)\n",
        "        pred_i = (pred_mask == i)\n",
        "        #print(f\"Class {i}: true_i sum: {torch.sum(true_i)}, pred_i sum: {torch.sum(pred_i)}\")\n",
        "\n",
        "        iou = calculate_iou(true_i, pred_i)\n",
        "        #print(f\"Class {i} IoU: {iou}\")\n",
        "        class_iou.append(iou)\n",
        "\n",
        "    # Compute the mean IoU\n",
        "    if class_iou:\n",
        "        mean_iou = torch.mean(torch.tensor(class_iou))\n",
        "    else:\n",
        "        mean_iou = 0.0  # Handle case with no classes\n",
        "        #print(f\"Mean IoU: {mean_iou}\")\n",
        "    return mean_iou\n"
      ],
      "metadata": {
        "id": "1UyogskdBYWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Callback Function"
      ],
      "metadata": {
        "id": "yHANDpo3q_SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(pred_logits, target_size):\n",
        "    \"\"\"Create a mask from model logits.\"\"\"\n",
        "\n",
        "    # resize logits to match the ground truth size\n",
        "    pred_logits_resized = F.interpolate(\n",
        "        pred_logits,\n",
        "        size=target_size,\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "    pred_mask = torch.argmax(pred_logits_resized, dim=1)\n",
        "    return pred_mask"
      ],
      "metadata": {
        "id": "2YbCozdNSw-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def display_image(image, ground_truth_mask, predicted_mask):\n",
        "    \"\"\"\n",
        "    Display the input image, ground truth mask, and predicted mask side by side.\n",
        "\n",
        "    Args:\n",
        "        image (torch.Tensor): The input image tensor (C, H, W).\n",
        "        ground_truth_mask (torch.Tensor): The ground truth mask tensor (H, W).\n",
        "        predicted_mask (torch.Tensor): The predicted mask tensor (H, W).\n",
        "    \"\"\"\n",
        "    # Move the image and masks to the CPU and convert to NumPy\n",
        "    image = image.cpu().numpy().transpose(1, 2, 0)  # Convert (C, H, W) -> (H, W, C)\n",
        "    ground_truth_mask = ground_truth_mask.cpu().numpy()\n",
        "\n",
        "    # Select the first channel of the ground_truth_mask to display it as grayscale\n",
        "    # ground_truth_mask = ground_truth_mask[0]\n",
        "    #if predicted_mask is not None:\n",
        "\n",
        "    predicted_mask = predicted_mask.cpu().numpy()\n",
        "\n",
        "    # Normalize the image for display (optional: adjust depending on input range)\n",
        "    image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
        "\n",
        "    # Create a figure with 3 subplots\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axs[0].imshow(image)\n",
        "    axs[0].set_title(\"Input Image\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    axs[1].imshow(ground_truth_mask, cmap=\"jet\") # select the first channel\n",
        "    axs[1].set_title(\"Ground Truth Mask\")\n",
        "    axs[1].axis(\"off\")\n",
        "\n",
        "\n",
        "    #if predicted_mask is not None:\n",
        "    axs[2].imshow(predicted_mask, cmap=\"jet\")\n",
        "    axs[2].set_title(\"Predicted Mask\")\n",
        "    axs[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "q1yNuRveE9A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample mask unique values:\", torch.unique(batch['mask'][0]))\n",
        "display_image(\n",
        "    image=batch['pixel_values'][0],\n",
        "    ground_truth_mask=batch['mask'][0],\n",
        "    predicted_mask=None  # Skip predictions for raw data inspection\n",
        ")"
      ],
      "metadata": {
        "id": "7865xR4ZT-qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def custom_callback(epoch, model, val_loader, device):\n",
        "    \"\"\"\n",
        "    Callback function executed after each training epoch.\n",
        "    Evaluates the model on the validation set and calculates mean IoU.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    print(f\"Running validation for epoch {epoch + 1}...\")\n",
        "\n",
        "    total_mean_iou = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "        pixel_values = batch['pixel_values'].to(device)\n",
        "        true_mask = torch.argmax(batch['mask'].to(device), dim=1)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(pixel_values)\n",
        "        pred_mask = create_mask(outputs.logits, target_size=true_mask.shape[-2:])\n",
        "\n",
        "        # Compute mean IoU for the batch\n",
        "        mean_iou = calculate_mean_iou(true_mask, pred_mask)\n",
        "        total_mean_iou += mean_iou\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_mean_iou = total_mean_iou / num_batches\n",
        "    print(f\"Epoch {epoch + 1}: Mean IoU: {avg_mean_iou:.4f}\")\n",
        "\n",
        "\n",
        "    print(f\"Unique values in ground truth mask (batch): {torch.unique(batch['mask'])}\")\n",
        "    print(f\"Unique values in ground truth mask (per image): {torch.unique(true_mask[0])}\")\n",
        "\n",
        "    display_image(\n",
        "        image=pixel_values[0],  # First image in the batch\n",
        "        ground_truth_mask=true_mask[0],  # Ground truth mask for the first image\n",
        "        predicted_mask=pred_mask[0]  # Predicted mask for the first image\n",
        "      )\n"
      ],
      "metadata": {
        "id": "uxdyoKFyyRxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Run Training"
      ],
      "metadata": {
        "id": "5CMLZyCIlKmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F  # for the interpolate function\n",
        "\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, custom_callback):\n",
        "    \"\"\"\n",
        "    Trains the given model on the provided training data and displays predictions on validation data after each epoch.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        train_loader: DataLoader for training data.\n",
        "        val_loader: DataLoader for validation data.\n",
        "        optimizer: Optimizer for updating model parameters.\n",
        "        criterion: Loss function.\n",
        "        num_epochs: Number of training epochs.\n",
        "        device: Device to use for computation ('cuda' or 'cpu').\n",
        "        custom_callback: Callback function to execute after each epoch.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # Move the pixel_values and label tensors to the device\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "            labels = torch.argmax(batch['mask'].to(device), dim=1).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(pixel_values)\n",
        "\n",
        "            # Resize model outputs to match the input image size\n",
        "            outputs_resized = F.interpolate(\n",
        "                outputs.logits,  # assuming model returns logits\n",
        "                size=labels.shape[1:],  # match height and width of labels\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(outputs_resized, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "        # Execute the custom callback function after each epoch\n",
        "        custom_callback(epoch, model, val_loader, device)\n"
      ],
      "metadata": {
        "id": "pnuZr8-o34Rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, custom_callback)"
      ],
      "metadata": {
        "id": "n683XgZ6WqwO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}